# BioCortexAI

![Version](https://img.shields.io/badge/version-2.0--beta-blue)
![Python](https://img.shields.io/badge/python-3.9+-blue.svg)
![License](https://img.shields.io/badge/license-CC--BY--NC--4.0-lightgrey)

**BioCortexAI is a hybrid framework for stateful language models that combines a standard Transformer architecture with a biologically-inspired modulation layer called "PlantNet" and a phenomenological Digital Mirror for self-perception.**

Version 2.0-beta introduces full integration of the **Digital Mirror** module â€“ the model can now anticipate user responses and learn from prediction errors.

---

## ğŸ†• What's New in Version 2.0-beta

### ğŸª Digital Mirror

The model gains the ability to **see itself** from the other party's perspective:

- **Predictive loop**: The model generates a response, then predicts what the user will reply
- **Reality comparison**: The actual user response is compared with the prediction
- **Learning from error**: Prediction error modulates PlantNet hormones (cortisol on surprise, oxytocin on correct anticipation)
- **Embedding-space swap**: Sophisticated perspective transformation directly in vector space (not just regex replacement)

### ğŸ“Š Phenomenological Pipeline

Implementation of the theoretical concept `f(O_t; u, C, Î») â†’ R_t`:

| Component | Function | Description |
|-----------|----------|-------------|
| **Î¦** | `analyze_surface()` | Extraction of text surface features |
| **P_u** | `project_perception()` | Projection into observer's perceptual space |
| **M_Î»** | `apply_style()`, `deictic_swap()` | Mirror transformation (deixis, style) |
| **h** | `create_human_description()`, `assemble_agent_message()` | Output renderer |

---

## Key Features

- **Hybrid architecture**: Combination of a powerful LLM with a dynamic modulation network
- **Internal state (Mood)**: Modeled using a "hormone" system (dopamine, serotonin, cortisol, oxytocin)
- **ğŸª Self-reflection**: Model anticipates user reactions and learns from prediction error (NEW!)
- **Three levels of learning**: Short-term reactions, medium-term associative memory, long-term personality adaptation
- **Configurable**: All parameters in central `config.py`
- **Complete workflow**: Data preparation â†’ Pre-training â†’ Fine-tuning â†’ Export â†’ Chat

---

## How Does It Work?

The architecture operates in an extended feedback loop:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MAIN GENERATION LOOP                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. PlantNet â†’ Hormones â†’ LLM Modulation                            â”‚
â”‚  2. Modulated LLM â†’ Response Generation                             â”‚
â”‚  3. Feedback (logits, hidden_states, sentiment) â†’ PlantNet          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸª MIRROR PREDICTION LOOP (NEW!)                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  4. Model response â†’ Deictic swap (Iâ†”YOU) â†’ Swapped context         â”‚
â”‚  5. Model generates: "What do I think the user will reply?"         â”‚
â”‚  6. Store expectation vectors                                       â”‚
â”‚  7. Display original response to user                               â”‚
â”‚  8. User replies â†’ Compare with expectation â†’ Prediction error      â”‚
â”‚  9. Error modulates PlantNet hormones (learning)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Project Structure

```
/biocortex_ai
â”‚
â”œâ”€â”€ Model Core
â”‚   â”œâ”€â”€ config.py               # Central configuration for everything
â”‚   â”œâ”€â”€ model.py                # Transformer architecture definition
â”‚   â””â”€â”€ plant_net.py            # Biologically-inspired modulation network
â”‚
â”œâ”€â”€ Digital Mirror (NEW!)
â”‚   â”œâ”€â”€ mirror_module.py        # Phenomenological pipeline (Î¦, P_u, M_Î», h)
â”‚   â”œâ”€â”€ mirror_integration.py   # Integration into generation loop
â”‚   â””â”€â”€ swap_vector_utils.py    # Embedding-space perspective swap
â”‚
â”œâ”€â”€ Helper Modules
â”‚   â”œâ”€â”€ sentiment_analyzer.py   # User input sentiment analysis
â”‚   â””â”€â”€ install_dependencies.py # Dependency installation
â”‚
â”œâ”€â”€ Training Scripts
â”‚   â”œâ”€â”€ pretrain.py             # Base model pre-training
â”‚   â”œâ”€â”€ finetune.py             # Fine-tuning on conversational data
â”‚   â””â”€â”€ export_model.py         # Export to single .pth file
â”‚
â”œâ”€â”€ Inference
â”‚   â”œâ”€â”€ generate.py             # CLI generation with Mirror integration
â”‚   â””â”€â”€ chat_ui.py              # Gradio web interface
â”‚
â”œâ”€â”€ data_tools/                  # Data preparation
â”‚   â”œâ”€â”€ preprocess_corpus.py
â”‚   â”œâ”€â”€ prepare_tokenizer.py
â”‚   â””â”€â”€ chunk_corpus.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_data/               # Raw .txt files
â”‚   â””â”€â”€ CZ_QA_MIKRO.txt         # Sample dataset
â”‚
â””â”€â”€ checkpoints/
    â”œâ”€â”€ base_model/             # Pre-trained model
    â””â”€â”€ finetuned_model/        # Fine-tuned model
```

---

## Installation

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/YOUR_NAME/BioCortexAI.git
    cd BioCortexAI
    ```

2.  **(Recommended) Virtual environment:**
    ```bash
    python -m venv venv
    source venv/bin/activate  # Linux/macOS
    # venv\Scripts\activate   # Windows
    ```

3.  **Install dependencies:**
    ```bash
    python install_dependencies.py
    ```
    *Note: The sentiment analysis model (~1.1 GB) will be downloaded automatically.*

---

## Workflow

### 1. Data Preparation
```bash
python data_tools/preprocess_corpus.py
python data_tools/prepare_tokenizer.py
python data_tools/chunk_corpus.py
```

### 2. Model Training
```bash
python pretrain.py      # Pre-training
python finetune.py      # Fine-tuning
```

### 3. Model Export
```bash
python export_model.py --input checkpoints/finetuned_model/latest_checkpoint.pt --output biocortex_model.pth
```

### 4. ğŸª Swap Vector Derivation (NEW!)
For sophisticated embedding-space swap:
```bash
python swap_vector_utils.py --output swap_vector.pt
```

### 5. Model Interaction
```bash
python chat_ui.py       # Web interface (recommended)
python generate.py      # CLI mode
```

---

## Mirror Module Configuration

All mirror parameters are in `config.py`:

```python
# === Digital Mirror ===
USE_MIRROR_MODULE = True                    # Activate mirror loop

# Lambda parameters (transformation intensity)
MIRROR_LAMBDA_DEIXIS = 1.0                  # Full Iâ†”YOU swap
MIRROR_LAMBDA_STYL = 0.3                    # Mild style transformation

# Swap method
MIRROR_SWAP_METHOD = "embedding"            # "embedding" or "text"
SWAP_VECTOR_PATH = "swap_vector.pt"

# Threshold values for prediction evaluation
MIRROR_ERROR_THRESHOLD_LOW = 0.25           # Below this = good prediction
MIRROR_ERROR_THRESHOLD_HIGH = 0.60          # Above this = bad prediction

# Hormone modulation based on prediction quality
MIRROR_GOOD_PREDICTION = {
    "serotonin": +0.030,
    "oxytocin": +0.040,
}
MIRROR_BAD_PREDICTION = {
    "cortisol": +0.035,
    "dopamine": +0.025,
}

# Debug mode - displays detailed mirror outputs
MIRROR_DEBUG = True
```

---

## Mirror Debug Mode

When `MIRROR_DEBUG = True`, you will see in the console:

```
============================================================
[ğŸª MIRROR DEBUG] MIRROR PREDICTION LOOP
============================================================
[ğŸª MIRROR DEBUG] Lambda values:
    Î»_deixis = 1.0
    Î»_styl   = 0.3
============================================================
[ğŸª MIRROR DEBUG] ORIGINAL MODEL RESPONSE (before showing to user):
    "The meaning of life is subjective..."
============================================================
[ğŸª MIRROR DEBUG] SWAPPED CONTEXT (after deictic swap):
    model: What is the meaning of life? user: The meaning of life is...
============================================================
[ğŸª MIRROR DEBUG] EXPECTED USER RESPONSE (model's prediction):
    "That's an interesting thought..."
============================================================

[ğŸª MIRROR DEBUG] PREDICTION COMPARISON RESULT
============================================================
[ğŸª MIRROR DEBUG] Prediction Error: 0.3215
[ğŸª MIRROR DEBUG] Cosine Similarity: 0.6785
[ğŸª MIRROR DEBUG] Quality: â– NEUTRAL
============================================================
```

---

## Future Development

- [ ] Long-term memory of prediction patterns ("user model")
- [ ] Multi-level anticipation (prediction several turns ahead)
- [ ] Adaptive lambda parameters (learning optimal mirroring axes)
- [ ] Integration of additional observer profiles (critic, expert, layperson)
- [ ] Visualization of trajectory in perceptual space

---

## How to Contribute

Contributions are welcome! If you have an idea for improvement or found a bug, please open an "Issue" or submit a "Pull Request".

---

## License

This project is licensed under **Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)**.

You may freely share and adapt for non-commercial purposes, provided you give appropriate credit.

- **Full license text**: [CC BY-NC 4.0](https://creativecommons.org/licenses/by-nc/4.0/legalcode)

---

## Authors

**(c) 2025 OpenTechLab Jablonec nad Nisou s.r.o.**

Author: Michal Seidl
